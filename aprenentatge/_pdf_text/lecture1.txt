Lecture 1:
Introduction
Alberto ORTIZ RODRÃGUEZ
11752 Aprendizaje AutomÃ¡tico
11752 Machine Learning
MÃ¡ster Universitario
en Sistemas Inteligentes


Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

Machine learning in AI
â€¢ Artificial Intelligence, a couple of definitions
â€“ AI as a discipline:
A branch of computer science dealing with the simulation of intelligent behaviour in 
computers
â€“ AI as a property of a machine:
The capability of a machine to imitate intelligent human behaviour
â€¢ AI technologies
â€“ set of rich sub-disciplines 
and methodologies: 
â€¢ machine learning 
â€¢ intelligent sensor data 
processing
â€“ image processing & 
computer vision
â€¢ expert systems
â€¢ robotics
â€¢ â€¦
Alberto Ortiz (updated 23/09/2025)

Machine learning in AI
â€¢ Machine learning, a first definition
â€“ a subset of artificial intelligence in the field of computer science that makes use 
of a varied set of techniques to give computers 
â€¢ the ability to learn from data
â€“ solve a problem on the basis of â€œprevious experienceâ€ (= collected data)
â€“ maybe also progressively improve performance on the specific task 
â€¢ without being explicitly 
programmed
Alberto Ortiz (updated 23/09/2025)

Machine learning in AI
â€¢ A formalization of Machine Learning (from Tom Mitchell, CMU 1998)
â€“ Machine Learning is the study of algorithms that 
â€¢ improve their performance ğ‘ƒ
â€¢ at some task ğ‘‡
â€¢ with experience ğ¸
â€“ A well-defined learning task is given by < ğ‘‡, ğ¸, ğ‘ƒ >
â€¢ Some examples:
T: Recognizing hand-written words
E: Database of human-labeled images of handwritten 
words 
P: Percentage of words correctly classified
T: Playing checkers
E: Record of practice games
P: Percentage of games won against an arbitrary opponent
T: Driving on four-lane highways using vision sensors
E: A sequence of images and steering commands recorded 
while observing a human driver 
P: Average distance traveled before a human-judged error
T: Categorize email messages as spam or legitimate
E: Database of emails, with human-given labels
P: Percentage of email messages correctly classified
Alberto Ortiz (updated 23/09/2025)

Machine learning in AI
â€¢ Machine learning, a brief chronology
Alberto Ortiz (updated 23/09/2025)

Machine learning in AI
â€¢ Nowadays, we are experiencing the AI boom. Why now? 
â€“ We are now capable of addressing and solving hard problems
Alberto Ortiz (updated 23/09/2025)


Machine learning in AI
â€¢ Nowadays, we are experiencing the AI boom. Why now? 
â€“ We are now capable of addressing and solving hard problems
Alberto Ortiz (updated 23/09/2025)


Machine learning in AI
â€¢ Nowadays, we are experiencing the AI boom. Why now?
â€“ Availability of computational power
â€¢ Hardware (GPU, TPU) at reasonable cost
â€¢ Cloud computing
â€¢ Case of perception systems: availability of low-cost sensors, e.g. vision cameras
â€“ Availability of data
â€¢ Datasets publicly available in general 
â€¢ Tons of data produced and available, â€œbig dataâ€ (90% produced during the last years)
â€“ Democratization of tools
â€¢ Open source tools and frameworks
â€¢ Wide adoption in the research community 
and also companies
â€“ Economical value from AI
â€¢ More funding
â€¢ More research
â€¢ More applications
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example:
classify fish arriving on a conveyor belt 
based on the information provided by a 
vision camera
â€“ Discriminate between salmon and 
sea bass
â€“ The image is pre-processed as 
much as needed, e.g. isolate the fish 
instances that appear in the image 
(segmentation)
â€“ A feature extractor is able to 
measure key properties of every 
piece
â€“ A classifier runs on the selected 
features
(data flow can be bi-directional, stages can 
cooperate among them)
Description of the problem
pre-procesing
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ We can consider several properties of every piece:
â€¢ length
â€¢ brightness (i.e. gray-level)
â€¢ width
â€¢ number and shape of the fins 
â€¢ position of the mouth, etc.
â€“ One has to take into account the variability in the chosen property, together with: 
â€¢ Variations in the gray-level at every pixel:
â€“ Non-uniform reflectance
â€“ Non-uniform illumination
â€“ Shadows, specularities (glossiness)
â€¢ Position of the piece over the belt, 
â€¢ Camera noise,
â€¢ Noise from the pre-processing stage
ïƒ One cannot expect the same value in all measurements
control the image capture conditions
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example(cont.):
â€“ We have been informed that salmons tend to be shorter than sea bass pieces
â€“ We take a number of samples (= images) for training (200-300) and build a 
histogram:
â€“ As can be seen, the piece length by itself is a rather poor criterion to 
discriminate in a trustworthy way between the two species
Plus32
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ We consider another feature: the average gray level of the scales
â€“ The resulting histograms and the critical value ğ’™âˆ— are much more satisfactory 
since classes are better separated
Plus32
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ Feature selection and evaluation of the system
â€¢ associate a cost to each misclassification and optimize the cost among the different 
possible features 
â€“ Look for ğ’™âˆ— that minimizes the total cost to set an optimal decision rule
â€¢ so far we have assumed that the cost of a misclassification is symmetrical: it is just 
as wrong to confuse sea bass with salmon as it is to do the opposite
â€“ However, customers are not likely to think the same â€¦
ïƒ define the types of error and associate a different cost to each
â€“ Let us assume we have tested all the features separately. Now, it is turn to try 
with several features simultaneously â€¦
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ We observe that the sea bass tends to be wider than salmons â€¦
â€“ â€¦ and so we have a vector of features, so-called a descriptor:
the feature extractor has reduced the image of every piece to a point in a plane !!
â€“ The problem has now
become into partitioning
the feature space into two
regions and find a 
decision curve (2D)
Plus32
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ the best decision curve is that one that classifies in an optimal way the 
samples of the training set ?
â€“ would this model classify samples out from the training set with the same level 
of performance?
this decision curve is overfitted to the training set !! (overfitting)
Plus32
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ The following decision curve could be a good compromise between performance 
on the training set, simplicity of the classifier and behaviour with new samples
Plus32
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ A simple example (cont.):
â€“ The key point is that the classifier is capable of dealing well with as many 
unseen samples as possible â†’ problem of generalization
â€¢ It is not a matter of huge amounts of data, but of a training set well representing 
the classification problem
â€“ Notice that the classifier would be perfect only if all possible cases were 
available
â€¢ It is better a classifier not so good with the training set but that generalizes well and 
is capable of classifying correctly samples not used for training 
â€¢ On the other side:
â€“ William of Occam, 1280-1347? 
Entia non sunt multiplicanda praeter necessitatem
(entities should not be multiplied unless needed)
ï‚º under equal conditions, the simplest model is the likeliest to be 
correct
(Occamâ€™s razor)
Description of the problem
Alberto Ortiz (updated 23/09/2025)

â€¢ Description of the problem (cont.):
â€“ We could add other features: e.g. the eye color
â€¢ Features should be informative in order to separate better the classes
(= uncorrelated with the ones that we already have)
â€¢ New features should not reduce the effectivity of the classifier ïƒ remove noisy 
features
â€¢ The computational cost associated to calculating each new feature has to be taken 
into account
ï‚ŒWorking in n dimensions is not for free, adding a new dimension improves the 
effectivity in a significative way?
ï‚Real-time operation is necessary? Is it possible at the computational level?
e.g. recognize zip codes: conveyor belt for letters distribution moves at a 
speed of v cm/s to classify t letters per hour
Description of the problem
â†’ decision rule
(surface, hypersurface)
nD
Alberto Ortiz (updated 23/09/2025)

Basic concepts
â€¢ So far, some basic concepts from machine learning have emerged:
â€“ Samples are represented by means of descriptors
â€¢ Designed to capture the relevant information for the specific classification problem, 
aiming at removing any unnecessary complexity:
â€“ Ideally, the representation should disclose in a simple and natural way the 
structure of the classes in feature space
â€“ A good representation is a key aspect of any ML problem
â€¢ Usually, descriptors are n-dimensional vectors:
â€“ Vectors of real numbers:
â€“ Categorical data: 
Alberto Ortiz (updated 23/09/2025)

Basic concepts
â€¢ Hence the ML task becomes into working out a function ğ‘“ as follows:
âˆ’ If we know ğ‘“, we also have the separation curve between classes, which in turn defines 
the decision rule: single value, straight line, generic curve, surface, hyper-surface
Alberto Ortiz (updated 23/09/2025)

Basic concepts
â€¢ Solving the fish example:
import numpy as np
from sklearn import svm
import matplotlib.pyplot as plt
data = np.loadtxt('fish.txt')
X = data[:,1:-1]
y = data[:,-1]
# indices of classes
i0 = np.where(y == 0)[0]
i1 = np.where(y == 1)[0]
# class samples
X0 = X[i0,:]
y0 = y[i0]
X1 = X[i1,:]
y1 = y[i1]
# number of samples for each class
print('number of samples class 0: ',   
X0.shape[0], y0.shape[0])
print('number of samples class 1: ', 
X1.shape[0], y1.shape[0])
# ML model: straight line
clf = svm.LinearSVC(fit_intercept=True, random_state=0)
clf.fit(X, y) # training
# get the model parameters
w = clf.coef_[0]
a, b = w[0], w[1] 
c = clf.intercept_[0]
print('a = %.3f, b = %.3f, c = %.3f' % (a, b, c))
# plotting
plt.figure()
# plot samples    
plt.scatter(X0[:,0],X0[:,1],label='class 0') 
plt.scatter(X1[:,0],X1[:,1],label='class 1')
# plot model
yy = np.linspace(X[:,1].min(),X[:,1].max(),100)
plt.plot(-b/a * yy - c/a, yy, 'k:')
plt.legend()
plt.show()
# make two predictions
p = [4, 22]
l = clf.predict([p])[0]
print('predicted label for p = {} is {}'.format(p, l))
q = [6, 15]
l = clf.predict([q])[0]
print('predicted label for q = {} is {}'.format(q, l))
Alberto Ortiz (updated 23/09/2025)

Basic concepts
â€¢ Solving the fish example:
number of samples class 0:  74 74
number of samples class 1:  57 57
a = 0.455, b = 0.058, c = -3.328
predicted label for p = [4, 22] is 0.0
predicted label for q = [6, 15] is 1.0
Alberto Ortiz (updated 23/09/2025)

Basic concepts
â€¢ Hence the ML task becomes into working out a function ğ‘“ as follows:
âˆ’ If we know ğ‘“, we also have the separation curve between classes, which in turn defines 
the decision rule: single value, straight line, generic curve, surface, hyper-surface
â€¢ Once ğ‘“ has been determined, the model has to be evaluated:
CONFUSION MATRIX real positives real negatives
positive predictions TP FP
negative predictions FN TN
ğ´ =
TP+TN
TP+TN+FP+FN (accuracy)
Alberto Ortiz (updated 23/09/2025)

â€¢ RECAPITULATION: To solve a classification problem, it is important
â€“ to know how to generate features and choose the most appropriate ones
â€“ know as many classification techniques as posible, as well as their
strengths and weaknesses
â€¢ Some machine learning models:
â€“ Bayesian classifiers
â€“ Neural networks
â€“ Decision trees, etc.
â€¢ Although humans are able to move quickly, smoothly and without apparent effort from 
one classification task to another ...
â€¦ designing a universal classifier (capable of performing accurately in a wide 
variety of tasks) is yet an unsolved problem
â€“ each decision task may require different features and thus result into different 
decision rules with different effectiveness levels
â€“ each technique is suitable for one type of problem
Basic concepts
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

Regression tasks
â€¢ Goal. Find some functional description of data, often for predicting values for new inputs
â€“ Data involved: 
â€¢ ğ‘‹ = ğ‘µ samples
â€¢ ğ‘¦ = expected values instead of class labels
â€“ Learning based on the approximation error
â€¢ Meaningful examples:
â€“ Weather prediction
â€“ Stock market price prediction
â€“ Economical/Market trends capture and forecasting
â€“ etc.
Classification versus Regression
Straight line fitting:
given ğ‘¥ğ‘–, ğ‘¦ğ‘–  and
(in general, 
curve fitting)
ğ‘¦ = ğ‘ğ‘¥ + ğ‘
ğ‘, ğ‘ ?
ğ‘¥1 ğ‘¥2 ğ‘¥3 ğ‘¥4 ğ‘¦ = class
1 2 -4 3 1
3 2 2 2 1
2 5 3 2 2
2 4 2 3 2
1 1 0 2 1
6 2 4 1 2
Alberto Ortiz (updated 23/09/2025)

Regression tasks
â€¢ Example. M-degree polynomial curve fitting:  ğ‘¡ = ğ‘ğ‘€ğ‘¥ğ‘€ + ğ‘ğ‘€âˆ’1ğ‘¥ğ‘€âˆ’1 + â‹¯ + ğ‘1ğ‘¥ +  ğ‘0
â€“ Data involved: 
â€¢ ğ‘‹ = ğ‘µ samples
â€¢ ğ‘¦ = expected values 
(continuous variable)
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

The design cycle
â€¢ To design an ML / perception system one typically has to:
â€¢ can be a large part of the cost
â€¢ preliminary study with few samples but many more later
â€¢ how do you know if we have all the necessary samples?
â€¢ characteristics that separate classes well, invariant to irrelevant 
transformations, etc.
â€¢ useful prior knowledge: typical attributes, shape of classes, ...
â€¢ linear/no, single/ensemble, neural network / SVM / decision tree ...
â€¢ predict classifier behaviour, performance, complexity, etc.
â€¢ choose samples for training (training set)
â€¢ find the parameters of the classes if needed, e.g. distribution 
â€¢ determine the model parameters
â€¢ choose the samples for testing (test set) 
â€¢ detect overfitting, and other misbehaviours
â€¢ evaluate the classif. complexity and scalability (dimensions/classes)
collect samples
choose
characteristics
choose
the ML model
train
the model
evaluate
the model
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

ML and perception systems
â€¢ Perception and ML systems typically adhere to the following structure:
â€¢ difficulty = sensor characteristics and limitations: bandwidth, 
resolution, sensitivity, distortion, signal-to-noise ratio,... 
â€¢ isolate structures in the data: e.g. isolate objects in an image, 
isolate phonemes/words in sound, â€¦
â€¢ calculate each feature (= properties) of the chosen descriptor
â€¢ simple or complex calculations
â€¢ works with abstract entities
â€¢ typically, independent of the application domain
â€¢ difficulty = accurate predictions despite classes variability
â€¢ exploit context information to improve classification
â€“ e.g. T-E C-T in English would be completed as THE CAT
â€¢ combine classifiers: acoustic recognition + lip reading
data capture
(sensors)
pre-processing
extraction of
characteristics
classification
post-processing
decision
environment
Data
(do not 
come 
from a
sensor)
perception system
ML system
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

Flavours of machine learning
â€¢ A distinction is made between several types of learning:
â€“ supervised learning
â€¢ an expert labels each sample 
of the dataset
â€“ unsupervised learning
â€¢ there is no explicit expert
â€¢ grouping techniques (clustering)
Alberto Ortiz (updated 23/09/2025)

Flavours of machine learning
â€¢ A distinction is made between several types of learning:
â€“ supervised learning
â€¢ an expert tags each sample 
of the dataset
â€“ unsupervised learning
â€¢ there is no explicit expert, grouping techniques (clustering)
â€¢ ideally, the system looks for the natural structure of the data 
Alberto Ortiz (updated 23/09/2025)

Flavours of machine learning
â€¢ A distinction is made between several types of learning:
â€“ supervised learning
â€¢ an expert tags each sample 
of the dataset
â€“ unsupervised learning
â€¢ there is no explicit expert, grouping techniques (clustering)
â€¢ ideally, the system looks for the natural structure of the data 
â€“ reinforcement learning or learning with a critic
â€¢ the system learns how to make decisions by exploring the problem through a set of 
trials/interactions with the environment which lead to positive or negative rewards
Alberto Ortiz (updated 23/09/2025)

Contents
â€¢ Machine learning in the context of Artificial Intelligence
â€¢ Description of the problem and basic concepts
â€¢ Regression tasks
â€¢ ML design cycle
â€¢ Exploitation (maybe as part of a perception system)
â€¢ Flavours of machine learning
â€¢ Development framework (suggested)
Alberto Ortiz (updated 23/09/2025)

(suggested) Development framework
â€¢ Python 3.x (e.g. 3.13) 
(www.python.org)
â€¢ Numpy (numpy.org)
â€¢ Scikit-learn (scikit-learn.org)
â€¢ Pandas (pandas.pydata.org)
â€¢ Matplotlib (matplotlib.org)
â€¢ Other libraries as needed
â€¢ Anaconda (www.anaconda.com)
Alberto Ortiz (updated 23/09/2025)

(suggested) Development framework
â€¢ Spyder IDE (www.spyder-ide.org)
â€¢ JupyterLab (from inside Anaconda)
â€¢ Visual Studio IDE
(code.visualstudio.com)
Alberto Ortiz (updated 23/09/2025)

Lecture 1:
Introduction
Alberto ORTIZ RODRÃGUEZ
11752 Aprendizaje AutomÃ¡tico
11752 Machine Learning
MÃ¡ster Universitario
en Sistemas Inteligentes
