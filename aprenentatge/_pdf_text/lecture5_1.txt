Unsupervised Learning:
Introduction
Alberto ORTIZ RODRÃGUEZ
11752 Aprendizaje AutomÃ¡tico
11752 Machine Learning
MÃ¡ster Universitario
en Sistemas Inteligentes

Alberto Ortiz (last update 12/15/2025) 2
Contents
â€¢ Problem description
â€¢ Definition of clustering
â€¢ Proximity measures

3
Problem description
â€¢ In unsupervised learning (UL), a program does not learn 
from labelled data. Instead, it attempts to discover 
patterns in the data, i.e. learn the structure of the data
â€“ bring out patterns and structure within the data, 
maybe informative by itself 
or serve as a guide to further analysis, e.g. learn
the classes prior to supervised classification
â€“ known as exploratory analysis or 
knowledge discovery
â€¢ Using UL  terminology: discover groups of related 
observations within the data called clusters
â€“ clustering or cluster analysis
â€¢ assigns observations into groups such that samples 
in the same group are most similar to one another
â€“ e.g. discover segments of customers (marketing)
â€¢ More widely applicable than supervised learning: no need for labelled data
â€¢ Other names: Numerical taxonomy (biology), Typology (social sci.), Partitioning (graphs th.)
Alberto Ortiz (last update 15/12/2025)
feature space
output 1
output 2

4
Problem description
â€¢ Meaningful clusters can be of diverse
shapes:
â€“ This is problem dependent, 
i.e. problem semantics
â€“ Humans are very good at detecting clusters 
in two and three dimensions
â€¢ SL and UL can be thought as occupying 
opposite ends of a spectrum
â€¢ A different approach called semi-supervised learning (SSL) 
makes use of both supervised and unsupervised learning
â€“ The dataset is partially labelled
â€“ Located somewhere in-between SL and UL
Alberto Ortiz (last update 15/12/2025)


5
Contents
â€¢ Problem description
â€¢ Definition of clustering
â€¢ Proximity measures
Alberto Ortiz (last update 15/12/2025)

6
Definition of clustering
â€¢ A cluster consists of a number of similar objects, given a certain similarity criterion. 
â€¢ Other definitions (collected from here and there):
â€“ A cluster is a set of entities which are alike, while entities from different clusters are not 
alike
â€“ A cluster is an aggregation of points in the test space such that the distance between 
points in the same cluster is less than the distance between any point in the cluster and 
any point not in it
â€“ Clusters may be described as connected regions of a multi-dimensional space 
containing a relatively high density of points, separated from other such regions by a 
region containing a relatively low density of points
â€¢ A number of definitions based on rather vaguely defined terms which lead to a bunch 
of algorithms.
â€¢ In any case, the goal is to find 
the natural structure of the data, 
similarly to the human skill of 
grouping points in 2D/3D space,
but for any amount of dimensions.
Alberto Ortiz (last update 15/12/2025)


7
Definition of clustering
â€¢ Given a set of samples ğ‘‹ = {ğ‘¥1, ğ‘¥2, â€¦ , ğ‘¥ğ‘} defined in an L-dimensional space,
a first non-universal, but formal definition of clustering would be as follows:
an M-grouping of X is a partition of X into M sets ğ¶1, ğ¶2, â€¦ , ğ¶ğ‘€, so that
â€¢ Summing up, a clustering problem involves:
â€“ A set of unlabelled samples
â€“ A proximity measure ïƒƒ (either a similarity s or a dissimilarity d)
â€“ A clustering algorithm, from the many alternatives readily available:
Alberto Ortiz (last update 15/12/2025)
1. hierarchical
2. optimization-based
3. model-based
4. density-based
5. graph-based
6. competitive
7. valley-seeking
8. sequential
9. others â€¦


8
Contents
â€¢ Problem description
â€¢ Definition of clustering
â€¢ Proximity measures
Alberto Ortiz (last update 15/12/2025)

9
Proximity measures
â€¢ The proximity measure chosen plays a central role in cluster analysis
â€¢ Formal definition of similarity measure (SM) / dissimilarity measure (DM)
â€¢ A dissimilarity measure d among elements of a set X is a function such that:
and
â€¢ A similarity measure s among elements of a set X is a function such that:
andproximity 
measure 
over X
Alberto Ortiz (last update 15/12/2025)
e.g. d0 = 0
e.g. s0 = 1
(the more dissimilar, 
the greater)
(the more similar, 
the greater)
ğ‘ = (ğ‘1, ğ‘2)
ğ‘1, ğ‘2 = ğ‘

10
Proximity measures
â€¢ The concept can be extended to measure proximity between sets (clusters)
â€¢ Formal definition of similarity measure (SM) / dissimilarity measure (DM)
â€¢ A dissimilarity measure d among subsets U ïƒ X (U ïƒ P(X)) is a function such that:
and
â€¢ A similarity measure s among subsets U ïƒ X (U ïƒ P(X)) is a function such that:
and
proximity 
measure 
over P(X)
Alberto Ortiz (last update 15/12/2025)
(the more disimilar, 
the greater)
(the more similar, 
the greater)


11
Proximity measures
â€¢ A more restrictive concept is that of metric
â€“ A metric m among elements of a set X is a function such that
and
â€“ Captures the notion of dissimilarity
â€“ Not all dissimilarity measures are metrics
â€¢ An DM can be obtained from a SM using any monotonically decreasing function, e.g.
Alberto Ortiz (last update 15/12/2025)


12
Proximity measures
â€¢ Examples of proximity measures:
â€“ weighted Lp metric (or Minkowski measure) - DM
Alberto Ortiz (last update 15/12/2025)


13
Proximity measures
â€¢ Examples of proximity measures:
â€“ dot product â€“ SM
â€“ cosinus measure â€“ SM
â€“ Tanimoto measure â€“ SM
Alberto Ortiz (last update 15/12/2025)
consider descriptors as nD-vectors instead of nD-points
ï¡
a
b


14
Proximity measures
â€¢ The previous proximity measures are intended for quantitative, real-valued 
descriptors
â€¢ Other proximity measures for these kind of data are the following:
â€“ Canberra distance â€“ DM
â€“ Bray-Curtis distance (Sorensen distance) â€“ DM
â€“ correlation coefficient â€“ SM
Alberto Ortiz (last update 15/12/2025)


15
Proximity measures
â€¢ For other sorts of data we need other proximity functions
â€¢ Proximity functions for binary-valued descriptors, i.e. ai = yes/no, e.g.
â€“ Hamming/matching distances â€“ DM
â€“ Jaccardâ€™s coefficient â€“ SM (frequency of occurrence of 0s and 1s is not the same)
â€“ Jaccardâ€™s distance â€“ DM (frequency of occurrence of 0s and 1s is not the same)
Alberto Ortiz (last update 15/12/2025)


16
Proximity measures
â€¢ Proximity functions for nominal/categorical variables, e.g. ai = red | green | blue
â€“ Encode categorical values as binary values and make use of corresp. proximity functions
â€“ Example: a = (gender, colour) = (male | female, red | white | blue)
1.
2.
Alberto Ortiz (last update 15/12/2025)
be careful 
with coding !!
d(red,white) =
d(red,blue) <
d(white,blue)


17
Proximity measures
â€¢ Proximity functions for ordinal variables (i.e. there exists an order), 
e.g. ai = excellent | good | average | poor
â€“ Encode ordinal values as real values and make use of corresp. proximity functions
â€“ Example:
Alberto Ortiz (last update 15/12/2025)


18
Proximity measures
â€¢ Examples of proximity measures between points and clusters
... at a formal level, they are relevant, 
but, at a practical level, proximity measures 
are more useful when defined between clusters
ïƒƒ = DM or SM
cluster has no representative cluster has a representative ï­
Alberto Ortiz (last update 15/12/2025)
e.g.ïƒƒ is a DM  ïƒƒrep
ï­C
a
 ïƒƒmin
 ïƒƒmaxa

19
Proximity measures
â€¢ Examples of proximity measures between clusters
â€“ Be careful if your algorithm depends on ïƒƒâ€¢ being a metric: some of the previous 
functions may not be metric functions, e.g. ïƒƒmax when ïƒƒ is a DM, ïƒƒmin when ïƒƒ
is an SM, or ïƒƒavg either if ïƒƒ is a DM or an SM
each cluster has a
representative ï­
clusters have no 
representatives
Alberto Ortiz (last update 15/12/2025)
 ïƒƒmin
 ïƒƒmax
e.g.ïƒƒ is a DM
 ïƒƒmean
ï­1
ï­2

Unsupervised Learning:
Introduction
Alberto ORTIZ RODRÃGUEZ
11752 Aprendizaje AutomÃ¡tico
11752 Machine Learning
MÃ¡ster Universitario
en Sistemas Inteligentes